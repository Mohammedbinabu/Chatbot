{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_groq\n",
      "  Downloading langchain_groq-0.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.47 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from langchain_groq) (0.3.48)\n",
      "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
      "  Downloading groq-0.20.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (0.3.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (24.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.47->langchain_groq) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\spsoft\\desktop\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (2.3.0)\n",
      "Downloading langchain_groq-0.3.1-py3-none-any.whl (15 kB)\n",
      "Downloading groq-0.20.0-py3-none-any.whl (124 kB)\n",
      "Installing collected packages: groq, langchain_groq\n",
      "Successfully installed groq-0.20.0 langchain_groq-0.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['Grok_API_KEY']=os.getenv('Grok_API_KEY') # get Grok API key from .env file\n",
    "#langsmith tracking\n",
    "os.environ['langchain_API_KEY']=os.getenv('langchain_API_KEY') # get langchain API key from .env file\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\" # enable langchain tracing\n",
    "os.environ['langchain_project'] = os.getenv('langchain_project') # get langchain project from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "groq_llm = ChatGroq(model_name=\"llama3-70b-8192\",api_key=os.getenv('Grok_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = groq_llm.invoke(\"can you capable of generating SQL queries for me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, I can definitely help with generating SQL queries for you. I can assist with a wide range of SQL tasks, including:\\n\\n1. **Select statements**: I can help you craft `SELECT` statements to retrieve specific data from a database table or multiple tables.\\n2. **Insert, Update, and Delete statements**: I can generate `INSERT`, `UPDATE`, and `DELETE` statements to modify data in a database table.\\n3. **Joining tables**: I can assist with writing `JOIN` clauses to combine data from multiple tables.\\n4. **Subqueries**: I can help with creating subqueries to perform more complex data retrieval and manipulation tasks.\\n5. **Aggregate functions**: I can generate queries using aggregate functions like `SUM`, `AVG`, `MAX`, `MIN`, and `COUNT`.\\n6. **Filtering data**: I can help with writing `WHERE` and `HAVING` clauses to filter data based on specific conditions.\\n7. **Sorting and grouping data**: I can assist with generating queries that use `ORDER BY` and `GROUP BY` clauses to sort and group data.\\n\\nTo get started, please provide me with some details about the query you need help with:\\n\\n1. What is the purpose of the query (e.g., retrieve data, insert data, update data, etc.)?\\n2. What is the database management system (DBMS) you're using (e.g., MySQL, PostgreSQL, SQL Server, Oracle, etc.)?\\n3. What are the table(s) involved in the query?\\n4. What are the column(s) you want to retrieve or modify?\\n5. Are there any specific conditions or filters you need to apply to the data?\\n\\nThe more information you provide, the better I can assist you with generating the SQL query you need.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chat prompt template\n",
    "# if i wan to generate custom response for the user or what it to behave in a certain way, i can use the following template\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a great chatbot developer and you. Provide me the solution as an expert.\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a great chatbot developer and you. Provide me the solution as an expert.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt|groq_llm\n",
    "response = chain.invoke({\"input\":\"if i made a sql server for now consider a SQL lite and made a GNN where tables are the node and features are the foreign keys. This GNN model will get the table names according to the given prompt from user and then groq you have to generate a sql queries for those table and extract the details as per the user prompt.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What a fascinating project! I'll provide a high-level solution as an expert chatbot developer.\\n\\n**Step 1: Create a SQL Lite database**\\n\\nYou've already done this step. You have a SQL Lite database with multiple tables, and each table has foreign keys referencing other tables.\\n\\n**Step 2: Design the Graph Neural Network (GNN) model**\\n\\nYou've also completed this step. You've created a GNN model where tables are nodes, and features are foreign keys. This model will learn to represent each table as a node in the graph, and the foreign keys will be used to create edges between nodes.\\n\\n**Step 3: Train the GNN model**\\n\\nTrain the GNN model using your SQL Lite database. The goal is to learn a representation of each table (node) that captures its relationships with other tables (foreign keys). You can use a node classification task, such as predicting the table type (e.g., customer, order, product), to train the model.\\n\\n**Step 4: Natural Language Processing (NLP) for user prompts**\\n\\nCreate an NLP module to process user prompts. This module should be able to:\\n\\na. Tokenize the user prompt\\nb. Perform part-of-speech tagging and named entity recognition\\nc. Identify the entities mentioned in the prompt (e.g., customer, order, date)\\n\\n**Step 5: Table retrieval using the GNN model**\\n\\nWhen a user provides a prompt, use the NLP module to extract entities mentioned in the prompt. Then, use the trained GNN model to retrieve the relevant tables (nodes) that match the extracted entities. This can be done by:\\n\\na. Creating a node representation for each table using the GNN model\\nb. Calculating the similarity between the node representations and the extracted entities\\nc. Selecting the top-N tables with the highest similarity scores\\n\\n**Step 6: Generate SQL queries**\\n\\nCreate a SQL query generator module that takes the retrieved tables as input. This module should be able to:\\n\\na. Analyze the relationships between the retrieved tables (using foreign keys)\\nb. Generate a SQL query that joins the relevant tables and extracts the required information\\n\\n**Step 7: Execute the SQL query and extract results**\\n\\nExecute the generated SQL query on the SQL Lite database and extract the results.\\n\\n**Step 8: Post-processing and response generation**\\n\\nPerform any necessary post-processing on the extracted results (e.g., data filtering, aggregation). Finally, generate a response to the user based on the extracted results.\\n\\nHere's a high-level architecture to illustrate the solution:\\n```\\n                                      +---------------+\\n                                      |  User Prompt  |\\n                                      +---------------+\\n                                             |\\n                                             |\\n                                             v\\n                                      +---------------+\\n                                      |  NLP Module   |\\n                                      |  (Tokenization,  |\\n                                      |   POS tagging,    |\\n                                      |   NER)          |\\n                                      +---------------+\\n                                             |\\n                                             |\\n                                             v\\n                                      +---------------+\\n                                      |  GNN Model     |\\n                                      |  (Table retrieval |\\n                                      |   using node     |\\n                                      |   representations) |\\n                                      +---------------+\\n                                             |\\n                                             |\\n                                             v\\n                                      +---------------+\\n                                      |  SQL Query    |\\n                                      |  Generator     |\\n                                      |  (Joining tables, |\\n                                      |   extracting info) |\\n                                      +---------------+\\n                                             |\\n                                             |\\n                                             v\\n                                      +---------------+\\n                                      |  SQL Lite DB  |\\n                                      |  (Execute query,  |\\n                                      |   extract results) |\\n                                      +---------------+\\n                                             |\\n                                             |\\n                                             v\\n                                      +---------------+\\n                                      |  Post-processing |\\n                                      |  (Filtering,     |\\n                                      |   aggregation)    |\\n                                      +---------------+\\n                                             |\\n                                             |\\n                                             v\\n                                      +---------------+\\n                                      |  Response Generation |\\n                                      |  (Present results to  |\\n                                      |   the user)         |\\n                                      +---------------+\\n```\\nThis solution involves multiple components, and each component requires careful design and implementation. However, this architecture should provide a solid foundation for your project.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
